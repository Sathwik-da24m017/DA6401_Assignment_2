{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List, Dict, Any\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "import wandb\n",
    "from wandb.sdk.wandb_run import Run\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/sathwikpentela/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mda24m017\u001b[0m (\u001b[33mda24m017-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key='f56388c51b488c425a228537fd2d35e5498a3a91')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    img_size: int = 128\n",
    "    num_classes: int = 10\n",
    "    batch_size: int = 32\n",
    "    epochs: int = 10\n",
    "    filter_organization: str = \"double\"  # 'same', 'double', 'half'\n",
    "    activation: str = \"silu\"  # 'relu', 'gelu', 'silu', 'mish'\n",
    "    data_augmentation: bool = True\n",
    "    batch_norm: bool = True\n",
    "    dropout: float = 0.3\n",
    "    dense_neurons: int = 256\n",
    "    learning_rate: float = 1e-4\n",
    "\n",
    "# Sweep Configuration (for hyperparameter tuning)\n",
    "sweep_config = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"name\": \"val_acc\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"filter_organization\": {\"values\": [\"same\", \"double\", \"half\"]},\n",
    "        \"activation\": {\"values\": [\"relu\", \"gelu\", \"silu\", \"mish\"]},\n",
    "        \"data_augmentation\": {\"values\": [True, False]},\n",
    "        \"batch_norm\": {\"values\": [True, False]},\n",
    "        \"dropout\": {\"values\": [0.1, 0.2, 0.3]},\n",
    "        \"dense_neurons\": {\"values\": [128, 256, 512]},\n",
    "        \"learning_rate\": {\"values\": [1e-3, 1e-4]},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(pl.LightningModule):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.config = config\n",
    "\n",
    "        # Define filter progression\n",
    "        if config.filter_organization == \"same\":\n",
    "            filters = [32] * 5\n",
    "        elif config.filter_organization == \"double\":\n",
    "            filters = [32, 64, 128, 256, 512]\n",
    "        elif config.filter_organization == \"half\":\n",
    "            filters = [512, 256, 128, 64, 32]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid filter organization\")\n",
    "\n",
    "        # Build convolutional blocks\n",
    "        conv_blocks = []\n",
    "        in_channels = 3\n",
    "        for out_channels in filters:\n",
    "            conv_blocks.extend([\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(out_channels) if config.batch_norm else nn.Identity(),\n",
    "                self._get_activation(config.activation),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "            ])\n",
    "            in_channels = out_channels\n",
    "        self.conv_layers = nn.Sequential(*conv_blocks)\n",
    "\n",
    "        # Calculate flattened size\n",
    "        flattened_size = (config.img_size // (2 ** 5)) ** 2 * filters[-1]\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(flattened_size, config.dense_neurons)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.fc2 = nn.Linear(config.dense_neurons, config.num_classes)\n",
    "\n",
    "    def _get_activation(self, name: str) -> nn.Module:\n",
    "        activations = {\n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"gelu\": nn.GELU(),\n",
    "            \"silu\": nn.SiLU(),\n",
    "            \"mish\": nn.Mish(),\n",
    "        }\n",
    "        return activations.get(name.lower(), nn.ReLU())\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv_layers(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self._get_activation(self.config.activation)(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = (logits.argmax(1) == y).float().mean()\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        acc = (logits.argmax(1) == y).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "        return {\"val_loss\": loss, \"val_acc\": acc}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.config.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(config: ModelConfig) -> T.Compose:\n",
    "    base_transforms = [\n",
    "        T.Resize((config.img_size, config.img_size)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    "    if config.data_augmentation:\n",
    "        base_transforms.insert(1, T.RandomHorizontalFlip())\n",
    "        base_transforms.insert(2, T.RandomRotation(10))\n",
    "    return T.Compose(base_transforms)\n",
    "\n",
    "def prepare_data(config: ModelConfig) -> tuple[DataLoader, DataLoader]:\n",
    "    dataset = datasets.ImageFolder(\"inaturalist_12K/train\", transform=get_transforms(config))\n",
    "    \n",
    "    # Stratified split (alternative method)\n",
    "    class_indices = defaultdict(list)\n",
    "    for idx, (_, label) in enumerate(dataset.samples):\n",
    "        class_indices[label].append(idx)\n",
    "    \n",
    "    train_indices, val_indices = [], []\n",
    "    for label, indices in class_indices.items():\n",
    "        split = int(0.8 * len(indices))\n",
    "        train_indices.extend(indices[:split])\n",
    "        val_indices.extend(indices[split:])\n",
    "    \n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    val_dataset = Subset(dataset, val_indices)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sweep():\n",
    "    run = wandb.init()\n",
    "    config = run.config\n",
    "    \n",
    "    # Set the run name using the hyperparameters\n",
    "    run.name = f\"fo_{config.filter_organization}_act_{config.activation}_aug_{config.data_augmentation}_bn_{config.batch_norm}_do_{config.dropout}_dn_{config.dense_neurons}_lr_{config.learning_rate}\"\n",
    "    run.save()\n",
    "    \n",
    "    # Data\n",
    "    train_loader, val_loader = prepare_data(config)\n",
    "    \n",
    "    # Model\n",
    "    model = CustomCNN(config)\n",
    "    \n",
    "    # Logger & Trainer\n",
    "    wandb_logger = WandbLogger(project=\"da6401_assignment2\")\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=config.epochs,\n",
    "        logger=wandb_logger,\n",
    "        accelerator=\"auto\",\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "    run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start sweep\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"da6401_assignment2\")\n",
    "wandb.agent(sweep_id, train_sweep, count=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best_model():\n",
    "    \"\"\"Train the model with best hyperparameters found during the sweep\"\"\"\n",
    "    # Best configuration from sweep results\n",
    "    best_config = ModelConfig(\n",
    "        img_size=128,\n",
    "        num_classes=10,\n",
    "        batch_size=32,\n",
    "        epochs=10,\n",
    "        filter_organization=\"half\",\n",
    "        activation=\"silu\",\n",
    "        data_augmentation=True,\n",
    "        batch_norm=True,\n",
    "        dropout=0.2,\n",
    "        dense_neurons=512,\n",
    "        learning_rate=1e-4\n",
    "    )\n",
    "\n",
    "    # Initialize wandb run for best model\n",
    "    run = wandb.init(\n",
    "        project=\"da6401_assignment2\",\n",
    "        config=best_config.__dict__,\n",
    "        name=\"best_model_run\"\n",
    "    )\n",
    "    \n",
    "    # Prepare data\n",
    "    train_loader, val_loader = prepare_data(best_config)\n",
    "    \n",
    "    # Setup model checkpointing\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"val_acc\",\n",
    "        dirpath=\"model_checkpoints\",\n",
    "        filename=\"best_model-{epoch:02d}-{val_acc:.2f}\",\n",
    "        save_top_k=1,\n",
    "        mode=\"max\",\n",
    "        save_last=True\n",
    "    )\n",
    "    \n",
    "    # Initialize model and trainer\n",
    "    model = CustomCNN(best_config)\n",
    "    wandb_logger = WandbLogger(project=\"DA6401_Assignment2\", log_model=\"all\")\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=best_config.epochs,\n",
    "        logger=wandb_logger,\n",
    "        accelerator=\"auto\",\n",
    "        callbacks=[checkpoint_callback],\n",
    "        deterministic=True\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "    \n",
    "    # Save the best model as artifact\n",
    "    wandb.log_artifact(\n",
    "        checkpoint_callback.best_model_path,\n",
    "        name=\"best_cnn_model\",\n",
    "        type=\"model\"\n",
    "    )\n",
    "    \n",
    "    run.finish()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Reverse normalization for visualization\"\"\"\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    return tensor * std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model: CustomCNN, test_dataset: datasets.ImageFolder, run: Run):\n",
    "    \"\"\"Create 10x3 grid of sample predictions\"\"\"\n",
    "    # Collect 3 samples per class\n",
    "    samples = {i: [] for i in range(model.config.num_classes)}\n",
    "    for img, label in test_dataset:\n",
    "        if len(samples[label]) < 3:\n",
    "            samples[label].append(img)\n",
    "        if all(len(v) == 3 for v in samples.values()):\n",
    "            break\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = {}\n",
    "    for cls in range(model.config.num_classes):\n",
    "        imgs = torch.stack(samples[cls])\n",
    "        if torch.cuda.is_available():\n",
    "            imgs = imgs.cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(imgs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        predictions[cls] = preds.cpu().tolist()\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(10, 3, figsize=(12, 30))\n",
    "    \n",
    "    for cls in range(model.config.num_classes):\n",
    "        for j in range(3):\n",
    "            img = samples[cls][j]\n",
    "            img = denormalize(img)\n",
    "            \n",
    "            ax = axes[cls][j]\n",
    "            ax.imshow(img.permute(1, 2, 0))\n",
    "            ax.set_title(\n",
    "                f\"True: {test_dataset.classes[cls]}\\n\"\n",
    "                f\"Pred: {test_dataset.classes[predictions[cls][j]]}\"\n",
    "            )\n",
    "            ax.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    wandb.log({\"sample_predictions\": wandb.Image(fig)})\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_first_layer_filters(model: CustomCNN, run: Run):\n",
    "    \"\"\"Visualize filters from first convolutional layer\"\"\"\n",
    "    first_conv = model.conv_layers[0]\n",
    "    weights = first_conv.weight.data.cpu()\n",
    "    \n",
    "    # Normalize filter weights for visualization\n",
    "    weights = (weights - weights.min()) / (weights.max() - weights.min())\n",
    "    \n",
    "    # Create grid of filters\n",
    "    grid = torchvision.utils.make_grid(weights, nrow=8, padding=2)\n",
    "    \n",
    "    # Plot and log to wandb\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(grid.permute(1, 2, 0))\n",
    "    plt.title(\"First Layer Conv Filters\")\n",
    "    plt.axis(\"off\")\n",
    "    wandb.log({\"conv_filters\": wandb.Image(plt)})\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test_set():\n",
    "    \"\"\"Evaluate the best model on test data and visualize results\"\"\"\n",
    "    # Load best configuration\n",
    "    best_config = ModelConfig(\n",
    "        img_size=128,\n",
    "        num_classes=10,\n",
    "        batch_size=32,\n",
    "        epochs=10,\n",
    "        filter_organization=\"half\",\n",
    "        activation=\"silu\",\n",
    "        data_augmentation=True,\n",
    "        batch_norm=True,\n",
    "        dropout=0.2,\n",
    "        dense_neurons=512,\n",
    "        learning_rate=1e-4\n",
    "    )\n",
    "    \n",
    "    # Initialize wandb run for evaluation\n",
    "    run = wandb.init(project=\"da6401_assignment2\", job_type=\"evaluation\")\n",
    "    \n",
    "    # Prepare test data transforms (no augmentation)\n",
    "    test_transform = T.Compose([\n",
    "        T.Resize((best_config.img_size, best_config.img_size)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load test dataset\n",
    "    test_path = \"inaturalist_12K/test\"\n",
    "    if not os.path.exists(test_path):\n",
    "        test_path = \"inaturalist_12K/val\"  # Fallback if test folder not found\n",
    "    \n",
    "    test_dataset = datasets.ImageFolder(root=test_path, transform=test_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=best_config.batch_size, shuffle=False)\n",
    "    \n",
    "    # Load best model checkpoint\n",
    "    checkpoint_path = \"model_checkpoints/best_model.ckpt\"  # Update with your actual path\n",
    "    model = CustomCNN.load_from_checkpoint(\n",
    "        checkpoint_path,\n",
    "        config=best_config\n",
    "    )\n",
    "    model.eval()\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    \n",
    "    # Evaluate test performance\n",
    "    test_results = {\"correct\": 0, \"total\": 0, \"loss\": 0.0}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            x, y = batch\n",
    "            if torch.cuda.is_available():\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "                \n",
    "            logits = model(x)\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            \n",
    "            test_results[\"loss\"] += loss.item() * x.size(0)\n",
    "            test_results[\"correct\"] += (preds == y).sum().item()\n",
    "            test_results[\"total\"] += y.size(0)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    test_loss = test_results[\"loss\"] / test_results[\"total\"]\n",
    "    test_acc = test_results[\"correct\"] / test_results[\"total\"]\n",
    "    \n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    wandb.log({\"test_loss\": test_loss, \"test_acc\": test_acc})\n",
    "    \n",
    "    # Visualization: Sample predictions\n",
    "    visualize_predictions(model, test_dataset, run)\n",
    "    \n",
    "    # Visualization: First layer filters\n",
    "    visualize_first_layer_filters(model, run)\n",
    "    \n",
    "    run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sathwikpentela/MTECH/DL/Assignment 2/DA6401_Assignment_2/wandb/run-20250419_223319-6z6cphu9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/da24m017-indian-institute-of-technology-madras/da6401_assignment2/runs/6z6cphu9' target=\"_blank\">best_model_run</a></strong> to <a href='https://wandb.ai/da24m017-indian-institute-of-technology-madras/da6401_assignment2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/da24m017-indian-institute-of-technology-madras/da6401_assignment2' target=\"_blank\">https://wandb.ai/da24m017-indian-institute-of-technology-madras/da6401_assignment2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/da24m017-indian-institute-of-technology-madras/da6401_assignment2/runs/6z6cphu9' target=\"_blank\">https://wandb.ai/da24m017-indian-institute-of-technology-madras/da6401_assignment2/runs/6z6cphu9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/sathwikpentela/miniforge3/envs/codify/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "\n",
      "  | Name        | Type       | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | conv_layers | Sequential | 1.6 M  | train\n",
      "1 | fc1         | Linear     | 262 K  | train\n",
      "2 | dropout     | Dropout    | 0      | train\n",
      "3 | fc2         | Linear     | 5.1 K  | train\n",
      "---------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.405     Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c7b18c8de14e6ca8f4c3afb803e913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sathwikpentela/miniforge3/envs/codify/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/sathwikpentela/miniforge3/envs/codify/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8bf1c985d3437b80b8982033d99cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d560a546f34bb59f19038f33b4a3d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6defb91652164758ba9144c39bf450bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069453520c4042d683dc22cf24439eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_best_model()\n",
    "    evaluate_on_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
